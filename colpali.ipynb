{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import pandas as pd \n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hf_key.txt', 'r') as file:\n",
    "    hf_key = file.read().strip()\n",
    "\n",
    "with open(\"openai_api_key.txt\", \"r\") as file:\n",
    "    openai_key = file.read().strip()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = hf_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"ibm/finqa\", trust_remote_code=True)\n",
    "\n",
    "# Access the splits\n",
    "data = dataset['train'].to_pandas()\n",
    "validation_data = dataset['validation'].to_pandas()\n",
    "test_data = dataset['test'].to_pandas()\n",
    "\n",
    "data = pd.concat([data, validation_data, test_data])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = data[[\"id\", \"question\", \"answer\", \"gold_inds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Company\"] = [row[0] for row in data.id.str.split(\"/\")]\n",
    "data[\"Year\"] = [row[1] for row in data.id.str.split(\"/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_companies = set(data.Company.unique())\n",
    "\n",
    "needed_years = {}\n",
    "\n",
    "for company in unique_companies:\n",
    "    needed_years[company] = list(data[data.Company == company].Year.unique())\n",
    "\n",
    "file_count = 0\n",
    "\n",
    "for company in needed_years.keys():\n",
    "    for year in needed_years[company]:\n",
    "        try:\n",
    "            file_count += len(os.listdir(f\"docs/{company}/{year}/\"))\n",
    "        except:\n",
    "            print(f\"docs/{company}/{year}/\")\n",
    "            \n",
    "file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.Company == \"AAL\" )& (data.Year == \"2014\")]\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG = RAGMultiModalModel.from_pretrained(\"vidore/colqwen2-v1.0\", device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG.index(\n",
    "    input_path=\"docs/temp/\",\n",
    "    index_name=\"finqa\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\"AAL\"]\n",
    "\n",
    "for company in companies:\n",
    "\n",
    "    years = os.listdir(f\"docs/{company}/\")\n",
    "    years = [\"2014\"]\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        pages = os.listdir(f\"docs/{company}/{year}/\")\n",
    "\n",
    "        for page in pages:\n",
    "            \n",
    "            RAG.add_to_index(\n",
    "                input_item=f\"docs/{company}/{year}/{page}\",\n",
    "                store_collection_with_index=True,\n",
    "                metadata={\"Company\": company, \"Year\": year, \"Page\" : page},\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prompt(image, question):\n",
    "\n",
    "    query = f\"\"\"\n",
    "    Answer the following query based solely on the provided image,  Give a short answer, 2-3 words at most. Then explain the steps you took to arrive at your answer.\n",
    "\n",
    "    Query: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": query},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/pdf;base64,{image}\"},\n",
    "        },\n",
    "    ],\n",
    "    )\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"Retrieved Context\",\"Correct Documents\", \"Generated Answer\", \"Correct Answer\"], index=data.index)\n",
    "\n",
    "for idx, query in data.question.items():\n",
    "\n",
    "    company = data.loc[idx].Company\n",
    "    year = data.loc[idx].Year\n",
    "\n",
    "    retrieved = RAG.search(query, k = 1, filter_metadata={\"Company\": company, \"Year\": year})\n",
    "    \n",
    "    results.loc[idx, \"Retrieved Context\"] = company + \"/\" +  year + \"/\" +  retrieved[0].metadata[\"Page\"]\n",
    "    results.loc[idx, \"Generated Answer\"] = model.invoke( [image_prompt(retrieved[0][\"base64\"], query) ]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Correct Answer\"] = data.answer\n",
    "results[\"Correct Documents\"] = data.id\n",
    "results[\"Golden Context\"] = data.gold_inds\n",
    "\n",
    "results.to_csv(\"colpali.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
